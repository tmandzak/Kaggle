{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [\"../generated/sources_rates.hdf5\",\n",
    "             \"../generated/pulishers_rates.hdf5\",\n",
    "             \"../generated/topics_rates.hdf5\",\n",
    "             \"../generated/ent_rates.hdf5\",\n",
    "             \"../generated/cat_rates.hdf5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>document_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>platform</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>traffic_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1fd5f051fba643</td>\n",
       "      <td>120</td>\n",
       "      <td>31905835</td>\n",
       "      <td>1</td>\n",
       "      <td>RS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8557aa9004be3b</td>\n",
       "      <td>120</td>\n",
       "      <td>32053104</td>\n",
       "      <td>1</td>\n",
       "      <td>VN&gt;44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c351b277a358f0</td>\n",
       "      <td>120</td>\n",
       "      <td>54013023</td>\n",
       "      <td>1</td>\n",
       "      <td>KR&gt;12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8205775c5387f9</td>\n",
       "      <td>120</td>\n",
       "      <td>44196592</td>\n",
       "      <td>1</td>\n",
       "      <td>IN&gt;16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9cb0ccd8458371</td>\n",
       "      <td>120</td>\n",
       "      <td>65817371</td>\n",
       "      <td>1</td>\n",
       "      <td>US&gt;CA&gt;807</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             uuid  document_id  timestamp  platform geo_location  \\\n",
       "0  1fd5f051fba643          120   31905835         1           RS   \n",
       "1  8557aa9004be3b          120   32053104         1        VN>44   \n",
       "2  c351b277a358f0          120   54013023         1        KR>12   \n",
       "3  8205775c5387f9          120   44196592         1        IN>16   \n",
       "4  9cb0ccd8458371          120   65817371         1    US>CA>807   \n",
       "\n",
       "   traffic_source  \n",
       "0               2  \n",
       "1               2  \n",
       "2               1  \n",
       "3               2  \n",
       "4               2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../download/page_views.csv\", nrows=10).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Contetnt popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load page_view grouped \n",
    "As needed for calculation of popularity (#viewed) for content: meta, topics, categories and entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"../generated/page_view_grouped_for_meta.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_page_view(filename, chunksize= 10 * 10 ** 6):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    loop = 0\n",
    "    len_grouped = 0\n",
    "    \n",
    "    iterator = pd.read_csv(\"../download/page_views.csv\", chunksize=chunksize, usecols=['document_id', 'platform', 'geo_location', 'traffic_source'], dtype={'document_id':int, 'platform':int, 'geo_location':str, 'traffic_source':int})\n",
    "    \n",
    "    for chunk in iterator:\n",
    "        chunk.fillna({'geo_location':'na'},inplace=True)\n",
    "    \n",
    "        group = pd.DataFrame({'viewed':chunk.groupby(['document_id', 'platform', 'geo_location', 'traffic_source']).size()}).reset_index()\n",
    "        group.to_hdf(filename, key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "\n",
    "        loop += 1\n",
    "        len_grouped += len(group)\n",
    "    \n",
    "        print loop, len_grouped\n",
    "        \n",
    "    return len_grouped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_page_view_next(filename, prev_filename='', chunksize= 10 * 10 ** 6):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    loop = 0\n",
    "    len_grouped = 0\n",
    "    \n",
    "    iterator = pd.read_hdf(prev_filename, chunksize=chunksize)\n",
    "    \n",
    "    for chunk in iterator:\n",
    "        group = pd.DataFrame({'viewed':chunk.groupby(['document_id', 'platform', 'geo_location', 'traffic_source'])['viewed'].sum()}).reset_index()\n",
    "        group.to_hdf(filename, key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "\n",
    "        loop += 1\n",
    "        len_grouped += len(group)\n",
    "    \n",
    "        print loop, len_grouped\n",
    "        \n",
    "    return len_grouped  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print 'Step '+str(i)\n",
    "current_len = group_page_view(filename+'.'+str(i))\n",
    "print current_len"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step 0\n",
    "1 2756083\n",
    "2 5483323\n",
    "3 8502676\n",
    "4 11462271\n",
    "5 14386422\n",
    "....\n",
    "201 582775034\n",
    "202 584538176\n",
    "203 586151805\n",
    "204 586781833\n",
    "586781833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "current_len = 586781833\n",
    "pd.read_hdf(filename+'.'+str(i), stop = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i+=1\n",
    "next_len = group_page_view_next(filename = filename+'.'+str(i), prev_filename = filename+'.0')\n",
    "print next_len"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 9999267\n",
    "2 19999183\n",
    "3 29997522\n",
    "4 39997228\n",
    "5 49997221\n",
    "...\n",
    "55 549920941\n",
    "56 559920890\n",
    "57 569919480\n",
    "58 579903214\n",
    "59 586684201\n",
    "586684201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "586684201 - current_len"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#never run\n",
    "while next_len < current_len:\n",
    "    current_len = next_len\n",
    "    i+=1\n",
    "    print 'Step '+str(i)\n",
    "    next_len = group_page_view(filename = filename+'.'+str(i), prev_filename = filename+'.'+str(i-1))\n",
    "    print next_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load content tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_meta = pd.read_csv(\"../download/documents_meta.csv\", usecols=['document_id', 'source_id', 'publisher_id']).fillna(-1)\n",
    "docs_meta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_topics = pd.read_csv(\"../download/documents_topics.csv\")\n",
    "docs_topics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_ent = pd.read_csv(\"../download/documents_entities.csv\")\n",
    "docs_ent.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_cat = pd.read_csv(\"../download/documents_categories.csv\")\n",
    "docs_cat.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(\"../generated/page_view_grouped_for_meta.hdf5.1\", stop = 5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def page_view_grouped_join_meta(input_filename, filenames, chunksize = 10 ** 6):\n",
    "    for fn in filenames:\n",
    "        try:\n",
    "            os.remove(fn)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    loop = 0\n",
    "    len_source, len_publisher, let_topics, len_ent, len_cat = 0, 0, 0, 0, 0\n",
    "    \n",
    "    for chunk in pd.read_hdf(input_filename, chunksize=chunksize):\n",
    "        chunk_meta = pd.merge(chunk, docs_meta, on='document_id')\n",
    "        chunk_meta.drop(['document_id'], axis=1, inplace=True)\n",
    "        chunk_source = pd.DataFrame({'source_viewed':chunk_meta.groupby(['source_id', 'platform', 'geo_location', 'traffic_source'])['viewed'].sum()}).reset_index()\n",
    "        chunk_publisher = pd.DataFrame({'publisher_viewed':chunk_meta.groupby(['publisher_id', 'platform', 'geo_location', 'traffic_source'])['viewed'].sum()}).reset_index()\n",
    "        del chunk_meta\n",
    "        len_source += len(chunk_source)\n",
    "        chunk_source.to_hdf(filenames[0], key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "        del chunk_source\n",
    "        len_publisher += len(chunk_publisher)\n",
    "        chunk_publisher.to_hdf(filenames[1], key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "        del chunk_publisher\n",
    "        \n",
    "        chunk_topics = pd.merge(chunk, docs_topics, on='document_id')\n",
    "        chunk_topics['topic_viewed'] = chunk_topics['viewed']*chunk_topics['confidence_level']\n",
    "        chunk_topics.drop(['document_id', 'viewed', 'confidence_level'], axis=1, inplace=True)\n",
    "        chunk_topics = pd.DataFrame({'topic_viewed':chunk_topics.groupby(['topic_id', 'platform', 'geo_location', 'traffic_source'])['topic_viewed'].sum()}).reset_index()\n",
    "        let_topics += len(chunk_topics)\n",
    "        chunk_topics.to_hdf(filenames[2], key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "        del chunk_topics\n",
    "        \n",
    "        chunk_ent = pd.merge(chunk, docs_ent, on='document_id')\n",
    "        chunk_ent['ent_viewed'] = chunk_ent['viewed']*chunk_ent['confidence_level']\n",
    "        chunk_ent.drop(['document_id', 'viewed', 'confidence_level'], axis=1, inplace=True)\n",
    "        chunk_ent = pd.DataFrame({'ent_viewed':chunk_ent.groupby(['entity_id', 'platform', 'geo_location', 'traffic_source'])['ent_viewed'].sum()}).reset_index()\n",
    "        len_ent += len(chunk_ent)\n",
    "        chunk_ent.to_hdf(filenames[3], key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "        del chunk_ent\n",
    "        \n",
    "        chunk_cat = pd.merge(chunk, docs_cat, on='document_id')\n",
    "        chunk_cat['cat_viewed'] = chunk_cat['viewed']*chunk_cat['confidence_level']\n",
    "        chunk_cat.drop(['document_id', 'viewed', 'confidence_level'], axis=1, inplace=True)\n",
    "        chunk_cat = pd.DataFrame({'cat_viewed':chunk_cat.groupby(['category_id', 'platform', 'geo_location', 'traffic_source'])['cat_viewed'].sum()}).reset_index()\n",
    "        len_cat += len(chunk_cat)\n",
    "        chunk_cat.to_hdf(filenames[4], key='default', mode='a', append=True, complevel=9, complib='zlib')\n",
    "        del chunk_cat\n",
    "        \n",
    "        loop += 1\n",
    "        print loop, len_source, len_publisher, let_topics, len_ent, len_cat\n",
    "        \n",
    "    return len_source, len_publisher, let_topics, len_ent, len_cat   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print 'Step '+str(i)\n",
    "print page_view_grouped_join_meta(\"../generated/page_view_grouped_for_meta.hdf5.1\", filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compacting new Content tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_content(filen, measure, dims, chunksize, step, ftype='hdf', suffix=''):\n",
    "    \n",
    "    if step == 0:\n",
    "        prev = filenames[filen] + suffix\n",
    "    else:\n",
    "        prev = filenames[filen] + suffix+'.'+str(step-1)\n",
    "        \n",
    "    output_filename = filenames[filen]+suffix+'.'+str(step)    \n",
    "\n",
    "    try:\n",
    "        os.remove(output_filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    len_total = 0\n",
    "    i = 0\n",
    "    \n",
    "    iterator = pd.read_hdf(prev, chunksize = chunksize) if ftype=='hdf' else pd.read_csv(prev, chunksize = chunksize)\n",
    "    \n",
    "    for chunk in iterator:\n",
    "        group = pd.DataFrame({measure: chunk.groupby(dims)[measure].sum()}).reset_index()\n",
    "                                                          \n",
    "        group.to_hdf(output_filename, key='default', mode='a', append=True, complevel=9, complib='zlib')                                                      \n",
    "                                                          \n",
    "        len_total += len(group)\n",
    "        i+=1\n",
    "        print i, len_total \n",
    "    \n",
    "    print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding geo_location (also cuts records with other locations not used in events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>geo_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>AD&gt;02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo geo_location\n",
       "0   -1           --\n",
       "1    0           A1\n",
       "2    1           A2\n",
       "3    2           AD\n",
       "4    3        AD>02"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_locations = pd.read_csv(\"../generated/geo_locations.csv\", dtype={'geo_location':str})\n",
    "geo_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo             2987\n",
       "geo_location    2987\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_locations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_geo_location(filename, next_filename, geo_locations, ftype='hdf'):\n",
    "    data = pd.read_hdf(filename)\n",
    "    index = (data['geo_location'] == '-->-->0') | (data['geo_location'] == 'na')\n",
    "    data.loc[index,'geo_location'] = '--'\n",
    "    \n",
    "    data = data.merge(geo_locations, on='geo_location')\n",
    "    data.drop('geo_location', axis=1, inplace=True)\n",
    "    \n",
    "    if ftype=='hdf':\n",
    "        data.to_hdf(next_filename, key='default', mode='w', complevel=5, complib='zlib')\n",
    "    else:    \n",
    "        data.to_csv(next_filename, index=False)\n",
    "        \n",
    "    return len(data), sum(data['geo'] == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>source_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>--&gt;--&gt;0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  platform geo_location  traffic_source  source_viewed\n",
       "0       -1.0         1           --               1             30\n",
       "1       -1.0         1           --               2             20\n",
       "2       -1.0         1           --               3              1\n",
       "3       -1.0         1      -->-->0               1              2\n",
       "4       -1.0         1           A1               1             10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure = 'source_viewed'\n",
    "dims = [u'source_id', u'platform', u'geo_location', u'traffic_source']\n",
    "#group_content(0, measure, dims, chunksize = 10 ** 7, step=0)  #~104 *10e6\n",
    "#group_content(0, measure, dims, chunksize = 10 ** 7, step=1)# 64,502,530\n",
    "#group_content(0, measure, dims, chunksize = 2 * 10 ** 7, step=2) # 36,038,451\n",
    "#group_content(0, measure, dims, chunksize = 3 * 10 ** 7, step=3) # ~21,000,000\n",
    "#group_content(0, measure, dims, chunksize = 3 * 10 ** 7, step=4) # 15,268,303\n",
    "#group_content(0, measure, dims, chunksize = 2 * 10 ** 7, step=5) # 15,268,303  FINAL\n",
    "pd.read_hdf(filenames[0]+'.5', stop = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print encode_geo_location(filenames[0]+'.5', filenames[0]+'.csv.6', geo_locations, ftype='csv')  #(15231938, 15150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv(filenames[0]+'.csv.6', nrows = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims = [u'source_id', u'platform', u'traffic_source', u'geo']\n",
    "print dims, measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_content(0, measure, dims, chunksize = 2 * 10 ** 7, step=7, ftype='csv', suffix='.csv') #15,225,546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>geo</th>\n",
       "      <th>source_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  platform  traffic_source  geo  source_viewed\n",
       "0       -1.0         1               1   -1             32\n",
       "1       -1.0         1               1    0             10\n",
       "2       -1.0         1               1   11             13\n",
       "3       -1.0         1               1   13             49\n",
       "4       -1.0         1               1   15              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(filenames[0]+'.csv.7', stop = 10).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measure = 'publisher_viewed'\n",
    "dims = [u'publisher_id', u'platform', u'geo_location', u'traffic_source']\n",
    "#group_content(1, measure, dims, chunksize = 2 * 10 ** 7, step=0) # 24,880,740\n",
    "#group_content(1, measure, dims, chunksize = 2 * 10 ** 7, step=1) #7,745,188\n",
    "#group_content(1, measure, dims, chunksize = 10 ** 7, step=2) #4,967,426\n",
    "#group_content(1, measure, dims, chunksize = 10 ** 7, step=3) #4,967,426  FINAL\n",
    "pd.read_hdf(filenames[1]+'.3', stop = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print encode_geo_location(filenames[1]+'.3', filenames[1]+'.csv.4', geo_locations, ftype='csv') #(4,938,588, 6188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = [u'publisher_id', u'platform', u'traffic_source', u'geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_content(1, measure, dims, chunksize = 10 ** 7, step=5, ftype='csv', suffix='.csv') #4,935,288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>geo</th>\n",
       "      <th>publisher_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publisher_id  platform  traffic_source  geo  publisher_viewed\n",
       "0          -1.0         1               1   -1                22\n",
       "1          -1.0         1               1    0                 8\n",
       "2          -1.0         1               1   11                12\n",
       "3          -1.0         1               1   13                33\n",
       "4          -1.0         1               1   15                 1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(filenames[1]+'.csv.5', stop = 10).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measure = u'topic_viewed'\n",
    "dims = [u'topic_id', u'platform', u'geo_location', u'traffic_source']\n",
    "#group_content(2, measure, dims, chunksize = 5* 10 ** 6, step=0)  # 206,947,198\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=1)  # 69,690,010\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=2)  # 29,792,622\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=3)  # 14,919,647\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=4)  # 10,508,890\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=5)  # 6,383,228\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=6)  # 5,925,270\n",
    "#group_content(2, measure, dims, chunksize = 10 ** 7, step=7)  # 5,925,270  FINAL\n",
    "pd.read_hdf(filenames[2]+'.7', stop = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print encode_geo_location(filenames[2]+'.7', filenames[2]+'.csv.8', geo_locations, ftype='csv') #(5,822,091, 7612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = [u'topic_id', u'platform', u'traffic_source', u'geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_content(2, measure, dims, chunksize = 10 ** 7, step=9, ftype='csv', suffix='.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>geo</th>\n",
       "      <th>topic_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.310514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.536388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.740327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  platform  traffic_source  geo  topic_viewed\n",
       "0         0         1               1   -1     20.310514\n",
       "1         0         1               1    0     38.536388\n",
       "2         0         1               1    1      4.740327\n",
       "3         0         1               1    2      0.186612\n",
       "4         0         1               1    4      0.037480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(filenames[2]+'.csv.9', stop = 10).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>ent_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000228e7d9e9975f14e5cc1aeebab6a6</td>\n",
       "      <td>1</td>\n",
       "      <td>US&gt;CT&gt;533</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000228e7d9e9975f14e5cc1aeebab6a6</td>\n",
       "      <td>1</td>\n",
       "      <td>US&gt;WA&gt;819</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000228e7d9e9975f14e5cc1aeebab6a6</td>\n",
       "      <td>2</td>\n",
       "      <td>US&gt;IL&gt;602</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000228e7d9e9975f14e5cc1aeebab6a6</td>\n",
       "      <td>2</td>\n",
       "      <td>US&gt;NY&gt;538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003a98bea82feeafa038d1b7e191bfe</td>\n",
       "      <td>1</td>\n",
       "      <td>AT&gt;06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.295132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          entity_id  platform geo_location  traffic_source  \\\n",
       "0  000228e7d9e9975f14e5cc1aeebab6a6         1    US>CT>533               2   \n",
       "1  000228e7d9e9975f14e5cc1aeebab6a6         1    US>WA>819               2   \n",
       "2  000228e7d9e9975f14e5cc1aeebab6a6         2    US>IL>602               2   \n",
       "3  000228e7d9e9975f14e5cc1aeebab6a6         2    US>NY>538               2   \n",
       "4  0003a98bea82feeafa038d1b7e191bfe         1        AT>06               2   \n",
       "\n",
       "   ent_viewed  \n",
       "0    0.853479  \n",
       "1    0.853479  \n",
       "2    0.853479  \n",
       "3    0.853479  \n",
       "4    0.295132  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(filenames[3], stop = 10).head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "next_filename = filenames[3] + '.0'\n",
    "\n",
    "try:\n",
    "    os.remove(next_filename)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "i = 0\n",
    "\n",
    "for data in pd.read_hdf(filenames[3], chunksize = 10 ** 7):\n",
    "    index = (data['geo_location'] == '-->-->0') | (data['geo_location'] == 'na')\n",
    "    data.loc[index,'geo_location'] = '--'\n",
    "    \n",
    "    data = data.merge(geo_locations, on='geo_location')\n",
    "    data.drop('geo_location', axis=1, inplace=True)\n",
    "    \n",
    "    data.to_hdf(next_filename, key='default', mode='a', append=True, complevel=5, complib='zlib')\n",
    "   \n",
    "    i += 1\n",
    "    print i, len(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "measure = u'ent_viewed'\n",
    "dims = [u'entity_id', u'platform', u'geo_location', u'traffic_source']\n",
    "#group_content(3, measure, dims, chunksize = 5 * 10 ** 6, step=0) #834,495,799\n",
    "\n",
    "#dims = [u'entity_id', u'platform']\n",
    "#group_content(3, measure, dims, chunksize = 5 * 10 ** 6, step=0, suffix='.platform') # ?\n",
    "#group_content(3, measure, dims, chunksize =  2 * 10 ** 7, step=1, suffix='.platform') #4,979,913\n",
    "#group_content(3, measure, dims, chunksize =  10 ** 7, step=2, suffix='.platform') # 3,284,996\n",
    "pd.read_hdf(filenames[3]+'.platform.2', stop = 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dims = [u'entity_id', u'traffic_source']\n",
    "#group_content(3, measure, dims, chunksize = 5 * 10 ** 6, step=0, suffix='.traffic') # 24,983,574\n",
    "#group_content(3, measure, dims, chunksize =  2 * 10 ** 7, step=1, suffix='.traffic') # 4,227,284\n",
    "#group_content(3, measure, dims, chunksize =  10 ** 7, step=2, suffix='.traffic') # 2,830,329\n",
    "#group_content(3, measure, dims, chunksize =  10 ** 7, step=3, suffix='.traffic') # 2,830,329  FINAL\n",
    "pd.read_hdf(filenames[3]+'.traffic.3', stop = 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dims = [u'entity_id', u'platform', u'traffic_source']\n",
    "#group_content(3, measure, dims, chunksize = 5 * 10 ** 6, step=0, suffix='.plat_traff') # 55,208,378\n",
    "#group_content(3, measure, dims, chunksize =  2 * 10 ** 7, step=1, suffix='.plat_traff') # 12,851,777\n",
    "#group_content(3, measure, dims, chunksize =  2 * 10 ** 7, step=2, suffix='.plat_traff') # 6,727,134\n",
    "#group_content(3, measure, dims, chunksize =  2 * 10 ** 7, step=3, suffix='.plat_traff') # 6,727,134\n",
    "pd.read_hdf(filenames[3]+'.plat_traff.3', stop = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measure = u'cat_viewed'\n",
    "dims = [u'category_id', u'platform', u'geo_location', u'traffic_source']\n",
    "#group_content(4, measure, dims, chunksize = 10 ** 7, step=0)  #19,530,552\n",
    "#group_content(4, measure, dims, chunksize = 10 ** 7, step=1)  #3,253,069\n",
    "#group_content(4, measure, dims, chunksize = 10 ** 7, step=2)  #1,792,992\n",
    "#group_content(4, measure, dims, chunksize = 10 ** 7, step=3)  #1,792,992  FINAL\n",
    "pd.read_hdf(filenames[4]+'.3', stop = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print encode_geo_location(filenames[4]+'.3', filenames[4]+'.csv.4', geo_locations, ftype='csv') #(1,755,953, 2222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = [u'category_id', u'platform', u'traffic_source', u'geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_content(4, measure, dims, chunksize = 10 ** 7, step=5, ftype='csv', suffix='.csv') #1,754,514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>geo</th>\n",
       "      <th>cat_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.822754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>239.240352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.141090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.128752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id  platform  traffic_source  geo  cat_viewed\n",
       "0         1000         1               1   -1   20.822754\n",
       "1         1000         1               1    0  239.240352\n",
       "2         1000         1               1    1    3.141090\n",
       "3         1000         1               1    5    0.032317\n",
       "4         1000         1               1    8    0.128752"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(filenames[4]+'.csv.5', stop = 10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
