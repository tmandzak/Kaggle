{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = { 'Semana' : int, 'Agencia_ID' : int, 'Canal_ID' : int, 'Ruta_SAK' : int, 'Cliente_ID' : int,\n",
    "               'NombreCliente' : str, 'Producto_ID' : int, 'NombreProducto' : str, 'Venta_uni_hoy' : int,\n",
    "               'Venta_hoy' : float, 'Dev_uni_proxima' : int, 'Dev_proxima' : float, 'Demanda_uni_equil' : int}\n",
    "\n",
    "train_cols = ['Cliente_ID', 'Producto_ID', 'Ruta_SAK', 'Agencia_ID', 'Canal_ID', 'Demanda_uni_equil']\n",
    "train_cols_Semana = ['Cliente_ID', 'Producto_ID', 'Ruta_SAK', 'Agencia_ID', 'Canal_ID', 'Semana', 'Demanda_uni_equil']\n",
    "test_cols_Semana = ['id', 'Producto_ID', 'Canal_ID', 'Cliente_ID', 'Ruta_SAK', 'Agencia_ID', 'Semana']\n",
    "test_cols = ['id', 'Producto_ID', 'Canal_ID', 'Cliente_ID', 'Ruta_SAK', 'Agencia_ID']\n",
    "\n",
    "target = 'Demanda_uni_equil'\n",
    "output_folder = 'output/outliers11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run 'outliers.ipynb'\n",
    "%run 'medcouple.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cols(feature):\n",
    "    res = []\n",
    "    feature_dict = {}\n",
    "    feature_dict['1'] = 'Cliente_ID'  \n",
    "    feature_dict['2'] = 'Producto_ID' \n",
    "    feature_dict['3'] = 'Canal_ID'    \n",
    "    feature_dict['4'] = 'Ruta_SAK'    \n",
    "    feature_dict['5'] = 'Agencia_ID'  \n",
    "    feature_dict['6'] = 'Semana'      \n",
    "    for i in str(feature):\n",
    "        if i in '123456':\n",
    "            res.append(feature_dict[i])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_full_list = ['12345', '1245', '1234', '124', '1235', '125', '123', '12', '2345', '245', '234', '24',\n",
    "                          '235', '25',\n",
    "                          '23', '1345', '145', '134', '14', '135',\n",
    "                          '15', '13', '1', '2', '345', '45', '35', '34', '4', '5'] #, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_full_list = ['12345', '12345a', '1245', '1234', '1235', '2345', '1345', '124', '125', '123', '12', '245', '234', '24',\n",
    "                          '235', '25',\n",
    "                          '23', '145', '134', '14', '135',\n",
    "                          '15', '13', '1', '2', '345', '45', '35', '34', '4', '5'] #, '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avg of avg\n",
    "feature_full_list = ['12345','1245','1234','124','1235','125','123','12','2345','245','235','234','24',\n",
    "                     '25','1345','145','134','14','135','15','13','1','23','345','45','2','35','34','3','5','4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avg of train\n",
    "feature_full_list = ['12345', '1245', '1234', '124', '1235', '125', '123', '12', '2345o 1o', '2345o', '245', '234', '24',\n",
    "                     '235', '25',\n",
    "                     '1345', '145', '134', '14', '23', '135',\n",
    "                     '15', '13', '1', '2', '345', '45', '35', '34', '4', '5', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avg of train\n",
    "feature_full_list = ['1245', '1234', '124', '1235', '125', '123', '12', '2345', '245', '234', '24',\n",
    "                     '235', '25',\n",
    "                     '1345', '145', '134', '14', '23', '135',\n",
    "                     '15', '13', '1', '2', '345', '45', '35', '34', '4', '5', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avg of 12345 o \n",
    "feature_full_list = ['12345', '1245o 3o', '1245o', '1234o 5o', '1234o', '124o', '1235o 4o', '1235o', '125o', '123o', '12o', '245o 3o 1o', '2345o',\n",
    "                     '245o', '234o 1o 5o', '234o', '24o', '235o 14o', '235o', '25o', '1345o 2o', '1345o', '145o', '134o', '14o', '23o',\n",
    "                     '135o', '15o', '13o', '1o', '2o', '345o', '45o', '34o', '35o', '4o', '5o', '3o']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avg of 12345 o \n",
    "feature_full_list = ['12345', '1245o', '1234o', '124o', '1235o', '125o', '123o', '12o', '245o 3o 1o', '245o 13o', '2345o 1o', '2345o',\n",
    "                     '245o', '234o', '24o', '235o', '25o', '1345o', '145o', '134o', '14o', '23o',\n",
    "                     '135o', '15o', '13o', '1o', '2o', '345o', '45o', '34o', '35o', '4o', '5o', '3o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avg of 12345 o \n",
    "feature_full_list = ['12345', '1245o', '1234o', '124o', '1235o', '125o', '123o', '12o', '2345o 1o', '2345o',\n",
    "                     '245o', '234o', '24o', '235o', '25o', '1345o', '145o', '134o', '14o', '23o',\n",
    "                     '135o', '15o', '13o', '1o', '2o', '345o', '45o', '34o', '35o', '4o', '5o', '3o']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# avg of train - 3\n",
    "feature_full_list = ['12345', '1245', '124', '125', '12', '245', '24',\n",
    "                     '25',\n",
    "                     '145', '14', \n",
    "                     '15',  '1', '2', '45', '4', '5']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "feature_full_list = ['1245', '1234', '124', '1235', '125', '123', '12', '2345', '245', '234', '24',\n",
    "                     '235', '25',\n",
    "                     '1345', '145', '134', '14', '23', '135',\n",
    "                     '15', '13', '1', '2', '345', '45', '35', '34', '4', '5', '3']\n",
    "feature_full_list_ = []\n",
    "\n",
    "for f in feature_full_list:\n",
    "    feature_full_list_.append(f+'m')\n",
    "\n",
    "feature_full_list = feature_full_list_\n",
    "\n",
    "feature_full_list = ['12345', '1245m', '1234m', '124m', '1235m', '125m', '123m', '12m', '2345m', '245m', '234m', '24m',\n",
    "                     '235m', '25m', '23m', '1345m', '145m', '134m', '14m', '135m', '15m', '13m', '1m', '2m', '345m', '45m', '34m', '35m', '4m', '5m', '3m']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_full_list = ['12345', '12345a', '1245', '1245a', '1234', '1234a', '124', '124a', '1235', '1235a', '125', '125a',\n",
    "                          '123', '123a', '12', '12a', '2345', '2345a', '245', '245a', '234', '234a', '24', '24a',\n",
    "                          '235', '235a', '25', '25a', \n",
    "                          '23', '23a', '1345', '1345a', '145', '145a', '134', '134a', '14', '14a', '135', '135a',\n",
    "                          '15', '15a', '13', '13a', '1', '1a', '2', '2a', '345', '345a', '45', '45a',\n",
    "                          '35', '35a', '34', '34a', '4', '4a', '5', '5a'] #, '3']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_full_list = ['12345', '12345a', '1245', '1245a', '1234', '1234a', '124', '124a', '1235', '1235a', '125', '125a',\n",
    "                          '123', '123a', '12', '12a', '2345', '2345a', '245', '245a', '234', '234a', '24', '24a',\n",
    "                          '235', '235a', '25', '25a', \n",
    "                          '23', '23a', '1345', '1345a', '145', '145a', '134', '134a', '14', '14a', '135', '135a',\n",
    "                          '15', '15a', '13', '13a', '1', '1a', '2', '2a', '345', '345a', '45', '45a',\n",
    "                          '35', '35a', '34', '34a', '4', '4a', '5', '5a'] #, '3']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# -3 gently\n",
    "feature_full_list = ['1245', '1245a', '124', '124a', '125', '125a',\n",
    "                          '12', '12a', '245', '245a', '24', '24a',\n",
    "                          '25', '25a', \n",
    "                          '23', '23a', '145', '145a', '14', '14a', \n",
    "                          '15', '15a', '1', '1a', '2', '2a', '45', '45a',\n",
    "                          '35', '35a', '34', '34a', '4', '4a', '5', '5a'] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# -5 gently\n",
    "feature_full_list = ['124', '124a', '125', '125a',\n",
    "                          '12', '12a', '24', '24a',\n",
    "                          '25', '25a', \n",
    "                          '23', '23a', '145', '145a', '14', '14a', \n",
    "                          '15', '15a', '1', '1a', '2', '2a', '45', '45a',\n",
    "                          '35', '35a', '34', '34a', '4', '4a', '5', '5a'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_sub_feature(data, target, sub_feature, folder, overwrite):\n",
    "    fname = folder + str(sub_feature)+'.csv'\n",
    "    \n",
    "    if overwrite or not(os.path.isfile(fname)):\n",
    "        groupby = get_cols(sub_feature)\n",
    "        g = data.groupby(by = groupby)[target]\n",
    "        #gm = g.sum()\n",
    "        #gs = g.size()\n",
    "        #gx = g.max()\n",
    "        #gres = (gm - gx)/(gs-1)\n",
    "\n",
    "        if sub_feature[-1] == 'a':#mean_outliers_skewed\n",
    "            ( pd.DataFrame({ sub_feature : data.groupby(by = groupby)[target].mean() }).reset_index() ).to_csv(fname, index = False)\n",
    "            #( pd.DataFrame(data.groupby(by = groupby)[target].agg({ sub_feature : np.mean, 'size' : np.size })).reset_index() ).to_csv(fname, index=False)\n",
    "            #( pd.DataFrame({sub_feature: g.agg(mean_outliers_skewed) }).reset_index() ).to_csv(fname, index=False)\n",
    "            #( pd.DataFrame({sub_feature: g.apply(lambda x: x.mean()) }).reset_index() ).to_csv(fname, index=False)\n",
    "            #df = pd.DataFrame({sub_feature: gres, 'size' : gs}).reset_index()\n",
    "            #df = df[df[sub_feature].notnull()]\n",
    "            #df.to_csv(fname, index=False)\n",
    "        elif sub_feature[-1] == 'm': \n",
    "            ( pd.DataFrame({ sub_feature : data.groupby(by = groupby)[target].median() }).reset_index() ).to_csv(fname, index = False)\n",
    "        elif sub_feature[-1] == 's': \n",
    "            df = pd.DataFrame({ 'size' : data.groupby(by = groupby)[target].size()\n",
    "                              }).reset_index() \n",
    "            df.to_csv(fname, index = False)\n",
    "        elif sub_feature[-1] == 'e': \n",
    "            df = pd.DataFrame({ 'Q1' : data.groupby(by = groupby)[target].quantile(0.25),\n",
    "                                'Q3' : data.groupby(by = groupby)[target].quantile(0.75)\n",
    "                              }).reset_index() \n",
    "            df['IQR'] = df['Q3'] - df['Q1']\n",
    "            df['L'] = df['Q1'] - 1.5*df['IQR']\n",
    "            df['U'] = df['Q3'] + 1.5*df['IQR']\n",
    "            df.drop('Q1', axis=1, inplace=True)\n",
    "            df.drop('Q3', axis=1, inplace=True)\n",
    "            \n",
    "            \n",
    "            df.to_csv(fname, index = False)            \n",
    "\n",
    "        elif sub_feature[-1] == 'c': \n",
    "            df = pd.DataFrame({ 'mc' : data.groupby(by = groupby)[target].apply(lambda x: medcouple_1d(x))\n",
    "                              }).reset_index() \n",
    "            df.to_csv(fname, index = False)  \n",
    "            \n",
    "        elif sub_feature[-1] == 'i': \n",
    "            df = pd.DataFrame({ 'L' : data.groupby(by = groupby)[target].quantile(0.25),\n",
    "                                'U' : data.groupby(by = groupby)[target].quantile(0.75),\n",
    "                              }).reset_index() \n",
    "            df['IQR'] = df['U'] - df['L']\n",
    "            \n",
    "            df.to_csv(fname, index = False)            \n",
    "            \n",
    "        elif sub_feature[-1] == 'x': \n",
    "            df = pd.DataFrame({ 'size' : data.groupby(by = groupby)[target].size(),\n",
    "                                'Q1' : data.groupby(by = groupby)[target].quantile(0.25),\n",
    "                                'Q3' : data.groupby(by = groupby)[target].quantile(0.75),\n",
    "                                'mc' : data.groupby(by = groupby)[target].apply(lambda x: medcouple_1d(x))\n",
    "                              }).reset_index() \n",
    "            df['IQR'] = df['Q3'] - df['Q1']\n",
    "            df['L'] = df['Q1'] - 1.5*df['IQR']\n",
    "            df['U'] = df['Q3'] + 1.5*df['IQR']\n",
    "            df.drop('Q1', axis=1, inplace=True)\n",
    "            df.drop('Q3', axis=1, inplace=True)\n",
    "            \n",
    "            df['id'] = np.linspace(start = 1, stop = len(df), num = len(df), dtype = int)\n",
    "            df.to_csv(fname, index = False)            \n",
    "        elif sub_feature[-1] == 'o': \n",
    "            data = merge_new_feature(data, sub_feature[:-1]+'s' , folder = output_folder)\n",
    "            \n",
    "            g = data[data['size'] > 4].groupby(by = groupby)[target]            \n",
    "            df = pd.DataFrame({ sub_feature : g.apply(lambda x: mean_outliers_skewed(x)) }).reset_index()\n",
    "            if len(df)>0:\n",
    "                df.to_csv(fname, index = False)\n",
    "                header = False\n",
    "                mode = 'a'\n",
    "            else:\n",
    "                header = True\n",
    "                mode = 'w'\n",
    "            '''\n",
    "            g = data[data['size'] < 4].groupby(by = groupby)[target]            \n",
    "            df = pd.DataFrame({ sub_feature : g.mean() }).reset_index()\n",
    "            if len(df)>0:\n",
    "                df.to_csv(fname, mode=mode, header = header, index = False)\n",
    "                header = False\n",
    "                mode = 'a'\n",
    "            else:\n",
    "                header = True\n",
    "                mode = 'w'\n",
    "            '''\n",
    "            g = data[data['size'] == 4].groupby(by = groupby)[target]\n",
    "            df = pd.DataFrame({ sub_feature : g.apply(lambda x: mean_outliers(x)) }).reset_index()\n",
    "            if len(df)>0:\n",
    "                df.to_csv(fname, mode=mode, header = header, index = False)  \n",
    "            \n",
    "            data.drop('size', axis=1, inplace=True)\n",
    "            \n",
    "            #df = pd.DataFrame({ sub_feature : g.apply(lambda x: mean_outliers(x) if (len(x) == 4) else None) }).reset_index()\n",
    "            #df[df[sub_feature].notnull()].to_csv(fname, mode='a', header = False, index = False)                     \n",
    "            \n",
    "        else:    \n",
    "            ( pd.DataFrame({ sub_feature : data.groupby(by = groupby)[target].mean() }).reset_index() ).to_csv(fname, index = False)\n",
    "            #( pd.DataFrame({ sub_feature : data.groupby(by = groupby)[target].median() }).reset_index() ).to_csv(fname)\n",
    "            #( pd.DataFrame(data.groupby(by = groupby)[target].agg({ sub_feature : median_outliers_skewed, 'size' : len })).reset_index() ).to_csv(fname, index=False)\n",
    "            #df = pd.DataFrame({ 'size' : g.size()}).reset_index() \n",
    "            #df = df[df['size']>4]\n",
    "            #df.drop('size', axis = 1, inplace=True)      \n",
    "            #( pd.DataFrame({ 'list' : g.apply(lambda x: list(x) if (len(x) > 1) else []) }).reset_index() ).to_csv(fname, index = False)                     \n",
    "            \n",
    "            #df[df[sub_feature].notnull()].to_csv(fname, index = False)                     \n",
    "                                 \n",
    "            \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_all_features(data, target, features, folder, overwrite = False):\n",
    "    print folder\n",
    "    for feature in features:\n",
    "        res = ''\n",
    "        for sub_feature in feature.split():\n",
    "            res = res + sub_feature + ' '\n",
    "            if build_sub_feature(data, target, sub_feature, folder, overwrite):\n",
    "                 res = res + '(created)  '\n",
    "        print res\n",
    "            \n",
    "    return 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_new_feature(data, feature, folder):\n",
    "    for sub_feature in feature.split():\n",
    "        groupby = get_cols(sub_feature)\n",
    "        f = pd.read_csv(folder + str(sub_feature)+'.csv', dtype = float )\n",
    "        #f.drop(f.columns[[0]], axis=1, inplace=True)\n",
    "        data = pd.merge(data, f, how='left', on = groupby)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_features(data, target, features, folder):\n",
    "    feature_evaluation_list = {}\n",
    "    print 'Start'\n",
    "    for feature in features:\n",
    "        data = merge_new_feature(data, feature, folder)\n",
    "        e = data[target] - data[feature]\n",
    "        del data[feature]\n",
    "        e = e[pd.notnull(e)]\n",
    "        feature_evaluation_list[feature] = np.dot(e, e) / len(e) \n",
    "        print feature, ' : ', feature_evaluation_list[feature]\n",
    "    print 'Done'    \n",
    "        \n",
    "    features_list_sorted = sorted(feature_evaluation_list, key=feature_evaluation_list.__getitem__)\n",
    "    \n",
    "    for feature in features_list_sorted:\n",
    "        print \"'\"+str(feature)+\"': \"+str(feature_evaluation_list[feature])\n",
    "    \n",
    "    print features_list_sorted     \n",
    "    \n",
    "    return features_list_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_feature(data, target, feature, folder):\n",
    "    outF = open(folder + \"train.txt\", \"a\")\n",
    "    print 'Merge ', feature \n",
    "    data = merge_new_feature(data, feature, folder)\n",
    "    data = data\n",
    "    H = pd.DataFrame()\n",
    "    sub_feature_list = feature.split()\n",
    "    \n",
    "    for i in range(0, len(sub_feature_list)):\n",
    "        data = data[data[sub_feature_list[i]].notnull()]\n",
    "    \n",
    "    for i in range(0, len(sub_feature_list)):\n",
    "        H[i] = data[sub_feature_list[i]]\n",
    "        #H[i].loc[H[i]==0] = 1e-3\n",
    "        #H[i] = np.log(H[i])\n",
    "    y = data[target]\n",
    "    #y.loc[y == 0] = 1e-3\n",
    "    #y = np.log(y)\n",
    "\n",
    "    print 'Train...'\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(H, y)\n",
    "    mRSS = mean_squared_error(model.predict(H), data[target])\n",
    "    #mRSS = mean_squared_error(np.exp(model.predict(H)), data[target])\n",
    "    \n",
    "    for i in range(0, len(sub_feature_list)):\n",
    "        del data[sub_feature_list[i]]\n",
    "    \n",
    "    w = [model.intercept_]\n",
    "    for i in range(0, len(sub_feature_list)):\n",
    "        w.append(model.coef_[i])\n",
    "    w.append(mRSS)\n",
    "\n",
    "    res = { feature: w}   \n",
    "    #print res    \n",
    "    print >>outF, res\n",
    "    outF.close()\n",
    "    \n",
    "    return res\n",
    "\n",
    "#print train_feature(train, target, feature='2a 3a', folder = output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_all_features(data, target, features,  folder):\n",
    "    features_trained = {}\n",
    "    for feature in features:\n",
    "        features_trained.update( train_feature(data, target, feature, folder) )\n",
    "        \n",
    "    features_trained_mRSS = {}\n",
    "    for f in features_trained:\n",
    "        features_trained_mRSS[f] = features_trained[f][-1]\n",
    "    \n",
    "    features_trained_sorted = sorted(features_trained_mRSS, key=features_trained_mRSS.__getitem__)\n",
    "    \n",
    "    for feature in features_trained_sorted:\n",
    "        print \"'\"+str(feature)+\"': \"+str(features_trained_mRSS[feature])\n",
    "    \n",
    "    print features_trained_sorted     \n",
    "        \n",
    "    return features_trained_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe_feature(feature, folder):\n",
    "    if 'a' in feature:\n",
    "        feature_ = feature#[:-1]\n",
    "    else:\n",
    "        feature_ = feature\n",
    "    f = pd.read_csv(folder + str(feature)+'.csv', dtype = float)\n",
    "    print f[feature_].describe()\n",
    "    plt.hist(f[feature_])\n",
    "    print f.head()\n",
    "    print f.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(feature, folder, dtype):\n",
    "    return pd.read_csv(folder + str(feature)+'.csv', dtype = dtype)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
